"""
Phase 5: ì•ˆì •ì„± ê²€ì¦ ëª¨ë“ˆ
ì‹œìŠ¤í…œì˜ ì¥ì‹œê°„ ìš´ì˜ ì•ˆì •ì„±, ì—ëŸ¬ ë³µêµ¬, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜, ë°ì´í„° ë¬´ê²°ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import time
import logging
import psutil
import gc
import threading
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

from .mock_unified_service import MockUnifiedMarketAnalysisService
from .error_handler import ErrorHandler
from .logging_service import LoggingService
from .cache_service import CacheService

logger = logging.getLogger(__name__)


class StabilityValidation:
    """ì•ˆì •ì„± ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.unified_service = MockUnifiedMarketAnalysisService()
        self.error_handler = ErrorHandler()
        self.logging_service = LoggingService()
        self.cache_service = CacheService()
        
        # ì•ˆì •ì„± ë©”íŠ¸ë¦­ ì €ì¥
        self.stability_metrics = {}
        self.validation_results = {}
        
    def long_running_test(self, hours: int = 24) -> Dict[str, Any]:
        """ì¥ì‹œê°„ ìš´ì˜ í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ›¡ï¸ ì¥ì‹œê°„ ìš´ì˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ëª©í‘œ: {hours}ì‹œê°„)")
        
        try:
            # ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” 24ì‹œê°„ì´ì§€ë§Œ, í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ë¶„ìœ¼ë¡œ ë‹¨ì¶•
            test_duration_minutes = min(hours * 60, 5)  # ìµœëŒ€ 5ë¶„ìœ¼ë¡œ ì œí•œ
            start_time = time.time()
            end_time = start_time + (test_duration_minutes * 60)
            
            # í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
            operation_count = 0
            error_count = 0
            memory_samples = []
            performance_samples = []
            max_iterations = 300  # ìµœëŒ€ 300íšŒ ë°˜ë³µìœ¼ë¡œ ì œí•œ
            
            # ì£¼ê¸°ì ì¸ ë©”ëª¨ë¦¬ ìƒ˜í”Œë§
            memory_monitor_thread = threading.Thread(
                target=self._monitor_memory_usage,
                args=(memory_samples, end_time),
                daemon=True
            )
            memory_monitor_thread.start()
            
            # ë©”ì¸ í…ŒìŠ¤íŠ¸ ë£¨í”„
            while time.time() < end_time and operation_count < max_iterations:
                try:
                    # ì£¼ê¸°ì ì¸ ë¶„ì„ ì‘ì—… ìˆ˜í–‰
                    if operation_count % 10 == 0:  # 10ë²ˆë§ˆë‹¤ í•œ ë²ˆì”©
                        start_analysis = time.time()
                        result = self.unified_service.analyze_single_stock_comprehensive(
                            ticker="005930.KS",
                            market_type="KOSPI",
                            timeframe="d"
                        )
                        analysis_time = time.time() - start_analysis
                        
                        performance_samples.append({
                            "operation_id": operation_count,
                            "analysis_time": analysis_time,
                            "success": result.get("success", False),
                            "timestamp": datetime.now().isoformat()
                        })
                    
                    operation_count += 1
                    time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
                    
                except Exception as e:
                    error_count += 1
                    logger.warning(f"ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸ ì¤‘ ì—ëŸ¬: {str(e)}")
                    self.error_handler.handle_analysis_error("long_running_test", str(e))
                    if error_count > 10:  # ì—ëŸ¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì¤‘ë‹¨
                        break
            
            # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚°
            actual_duration = time.time() - start_time
            
            # ë©”ëª¨ë¦¬ í†µê³„ ê³„ì‚°
            memory_stats = self._calculate_memory_statistics(memory_samples)
            
            # ì„±ëŠ¥ í†µê³„ ê³„ì‚°
            performance_stats = self._calculate_performance_statistics(performance_samples)
            
            results = {
                "test_duration_minutes": actual_duration / 60,
                "operation_count": operation_count,
                "error_count": error_count,
                "error_rate": error_count / operation_count if operation_count > 0 else 0,
                "memory_statistics": memory_stats,
                "performance_statistics": performance_stats,
                "success": error_count == 0,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ì¥ì‹œê°„ ìš´ì˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì‹¤í–‰ì‹œê°„: {actual_duration/60:.2f}ë¶„, ì—ëŸ¬ìœ¨: {results['error_rate']:.2%})")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì¥ì‹œê°„ ìš´ì˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def _monitor_memory_usage(self, memory_samples: List[Dict], end_time: float):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
        process = psutil.Process()
        
        while time.time() < end_time:
            try:
                memory_info = process.memory_info()
                memory_samples.append({
                    "rss_mb": memory_info.rss / 1024 / 1024,
                    "vms_mb": memory_info.vms / 1024 / 1024,
                    "timestamp": datetime.now().isoformat()
                })
                time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ìƒ˜í”Œë§
            except Exception as e:
                logger.warning(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ ì—ëŸ¬: {str(e)}")
    
    def _calculate_memory_statistics(self, memory_samples: List[Dict]) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ í†µê³„ ê³„ì‚°"""
        if not memory_samples:
            return {"error": "ë©”ëª¨ë¦¬ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."}
        
        rss_values = [sample["rss_mb"] for sample in memory_samples]
        vms_values = [sample["vms_mb"] for sample in memory_samples]
        
        return {
            "rss_statistics": {
                "min": min(rss_values),
                "max": max(rss_values),
                "avg": sum(rss_values) / len(rss_values),
                "current": rss_values[-1],
                "variance": max(rss_values) - min(rss_values)
            },
            "vms_statistics": {
                "min": min(vms_values),
                "max": max(vms_values),
                "avg": sum(vms_values) / len(vms_values),
                "current": vms_values[-1],
                "variance": max(vms_values) - min(vms_values)
            },
            "memory_stability": {
                "rss_stable": max(rss_values) - min(rss_values) < 50,  # 50MB ì´í•˜ ë³€ë™
                "vms_stable": max(vms_values) - min(vms_values) < 100,  # 100MB ì´í•˜ ë³€ë™
                "no_memory_leak": rss_values[-1] - rss_values[0] < 20  # 20MB ì´í•˜ ì¦ê°€
            }
        }
    
    def _calculate_performance_statistics(self, performance_samples: List[Dict]) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ê³„ì‚°"""
        if not performance_samples:
            return {"error": "ì„±ëŠ¥ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."}
        
        analysis_times = [sample["analysis_time"] for sample in performance_samples]
        success_count = sum(1 for sample in performance_samples if sample["success"])
        
        return {
            "analysis_time_statistics": {
                "min": min(analysis_times),
                "max": max(analysis_times),
                "avg": sum(analysis_times) / len(analysis_times),
                "current": analysis_times[-1]
            },
            "success_rate": success_count / len(performance_samples),
            "performance_stability": {
                "response_time_stable": max(analysis_times) - min(analysis_times) < 2.0,  # 2ì´ˆ ì´í•˜ ë³€ë™
                "consistent_success": success_count == len(performance_samples)
            }
        }
    
    def error_recovery_test(self) -> Dict[str, Any]:
        """ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ›¡ï¸ ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            # ë‹¤ì–‘í•œ ì—ëŸ¬ ìƒí™© í…ŒìŠ¤íŠ¸
            error_scenarios = [
                ("data_error", "ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨"),
                ("analysis_error", "ë¶„ì„ ì²˜ë¦¬ ì‹¤íŒ¨"),
                ("cache_error", "ìºì‹œ ì ‘ê·¼ ì‹¤íŒ¨"),
                ("network_error", "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨"),
                ("memory_error", "ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬"),
                ("timeout_error", "ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼"),
                ("validation_error", "ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨"),
                ("system_error", "ì‹œìŠ¤í…œ ì—ëŸ¬")
            ]
            
            recovery_results = []
            total_tests = len(error_scenarios)
            successful_recoveries = 0
            
            for error_type, error_message in error_scenarios:
                try:
                    # ì—ëŸ¬ ë°œìƒ ì‹œë®¬ë ˆì´ì…˜
                    if error_type == "data_error":
                        raise ValueError(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {error_message}")
                    elif error_type == "analysis_error":
                        raise RuntimeError(f"ë¶„ì„ ì²˜ë¦¬ ì‹¤íŒ¨: {error_message}")
                    elif error_type == "cache_error":
                        raise IOError(f"ìºì‹œ ì ‘ê·¼ ì‹¤íŒ¨: {error_message}")
                    elif error_type == "network_error":
                        raise ConnectionError(f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨: {error_message}")
                    elif error_type == "memory_error":
                        raise MemoryError(f"ë©”ëª¨ë¦¬ ë¶€ì¡±: {error_message}")
                    elif error_type == "timeout_error":
                        raise TimeoutError(f"ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼: {error_message}")
                    elif error_type == "validation_error":
                        raise ValueError(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {error_message}")
                    else:
                        raise Exception(f"ì‹œìŠ¤í…œ ì—ëŸ¬: {error_message}")
                    
                except Exception as e:
                    # ì—ëŸ¬ ë³µêµ¬ ì‹œë„
                    recovery_start = time.time()
                    try:
                        self.error_handler.handle_analysis_error(error_type, str(e))
                        recovery_time = time.time() - recovery_start
                        
                        recovery_results.append({
                            "error_type": error_type,
                            "error_message": error_message,
                            "recovery_success": True,
                            "recovery_time": recovery_time,
                            "error_handled": True
                        })
                        successful_recoveries += 1
                        
                    except Exception as recovery_error:
                        recovery_time = time.time() - recovery_start
                        recovery_results.append({
                            "error_type": error_type,
                            "error_message": error_message,
                            "recovery_success": False,
                            "recovery_time": recovery_time,
                            "error_handled": False,
                            "recovery_error": str(recovery_error)
                        })
            
            # ë³µêµ¬ ì„±ê³µë¥  ê³„ì‚°
            recovery_success_rate = successful_recoveries / total_tests if total_tests > 0 else 0
            
            # í‰ê·  ë³µêµ¬ ì‹œê°„ ê³„ì‚°
            successful_recoveries_times = [
                result["recovery_time"] for result in recovery_results 
                if result["recovery_success"]
            ]
            avg_recovery_time = sum(successful_recoveries_times) / len(successful_recoveries_times) if successful_recoveries_times else 0
            
            results = {
                "total_tests": total_tests,
                "successful_recoveries": successful_recoveries,
                "recovery_success_rate": recovery_success_rate,
                "average_recovery_time": avg_recovery_time,
                "recovery_results": recovery_results,
                "success": recovery_success_rate >= 0.8,  # 80% ì´ìƒ ì„±ê³µ
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì„±ê³µë¥ : {recovery_success_rate:.2%})")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def memory_leak_test(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ›¡ï¸ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            process = psutil.Process()
            
            # ì´ˆê¸° ë©”ëª¨ë¦¬ ì¸¡ì •
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            initial_vms = process.memory_info().vms / 1024 / 1024  # MB
            
            # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì‹œë®¬ë ˆì´ì…˜ (5íšŒ ë°˜ë³µ)
            memory_samples = []
            leaked_objects = []
            
            for cycle in range(5):
                cycle_start_memory = process.memory_info().rss / 1024 / 1024
                
                # ê°ì²´ ìƒì„± (ì¼ë¶€ëŠ” ëˆ„ìˆ˜)
                cycle_objects = []
                for i in range(100):
                    obj = {
                        "cycle": cycle,
                        "id": i,
                        "data": "x" * 1000,  # 1KB per object
                        "timestamp": datetime.now().isoformat()
                    }
                    cycle_objects.append(obj)
                
                # ì¼ë¶€ ê°ì²´ëŠ” ëˆ„ìˆ˜ (ì°¸ì¡° ìœ ì§€)
                if cycle % 2 == 0:
                    leaked_objects.extend(cycle_objects[:50])  # 50ê°œ ëˆ„ìˆ˜
                    cycle_objects = cycle_objects[50:]  # ë‚˜ë¨¸ì§€ ì •ë¦¬
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
                cycle_end_memory = process.memory_info().rss / 1024 / 1024
                
                memory_samples.append({
                    "cycle": cycle,
                    "start_memory_mb": cycle_start_memory,
                    "end_memory_mb": cycle_end_memory,
                    "memory_increase_mb": cycle_end_memory - cycle_start_memory,
                    "objects_created": len(cycle_objects) + len(leaked_objects),
                    "objects_leaked": len(leaked_objects),
                    "timestamp": datetime.now().isoformat()
                })
                
                # GC ì‹¤í–‰ (ì¼ë¶€ ì •ë¦¬)
                gc.collect()
                time.sleep(0.1)  # ì ì‹œ ëŒ€ê¸°
            
            # ìµœì¢… ë©”ëª¨ë¦¬ ì¸¡ì •
            final_memory = process.memory_info().rss / 1024 / 1024
            final_vms = process.memory_info().vms / 1024 / 1024
            
            # ëˆ„ìˆ˜ëœ ê°ì²´ ì •ë¦¬
            del leaked_objects
            gc.collect()
            
            # ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ì¸¡ì •
            cleaned_memory = process.memory_info().rss / 1024 / 1024
            cleaned_vms = process.memory_info().vms / 1024 / 1024
            
            # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¶„ì„
            total_memory_increase = final_memory - initial_memory
            memory_recovery = final_memory - cleaned_memory
            leak_detected = total_memory_increase > 10  # 10MB ì´ìƒ ì¦ê°€ ì‹œ ëˆ„ìˆ˜ë¡œ íŒë‹¨
            
            # ëˆ„ìˆ˜ íŒ¨í„´ ë¶„ì„
            memory_trend = []
            for i in range(1, len(memory_samples)):
                trend = memory_samples[i]["end_memory_mb"] - memory_samples[i-1]["end_memory_mb"]
                memory_trend.append(trend)
            
            consistent_increase = all(trend > 0 for trend in memory_trend) if memory_trend else False
            
            results = {
                "initial_memory_mb": initial_memory,
                "final_memory_mb": final_memory,
                "cleaned_memory_mb": cleaned_memory,
                "total_memory_increase_mb": total_memory_increase,
                "memory_recovery_mb": memory_recovery,
                "memory_samples": memory_samples,
                "memory_trend": memory_trend,
                "leak_analysis": {
                    "leak_detected": leak_detected,
                    "consistent_increase": consistent_increase,
                    "leak_size_mb": total_memory_increase,
                    "recovery_efficiency": memory_recovery / total_memory_increase if total_memory_increase > 0 else 0
                },
                "success": not leak_detected,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ëˆ„ìˆ˜ ê°ì§€: {leak_detected}, ì¦ê°€ëŸ‰: {total_memory_increase:.2f}MB)")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def data_integrity_test(self) -> Dict[str, Any]:
        """ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ›¡ï¸ ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            test_symbol = "005930.KS"
            integrity_results = []
            
            # ë™ì¼í•œ ë°ì´í„°ë¡œ ì—¬ëŸ¬ ë²ˆ ë¶„ì„ ìˆ˜í–‰
            for i in range(5):
                try:
                    start_time = time.time()
                    result = self.unified_service.analyze_single_stock_comprehensive(
                        ticker=test_symbol,
                        market_type="KOSPI",
                        timeframe="d"
                    )
                    analysis_time = time.time() - start_time
                    
                    integrity_results.append({
                        "iteration": i + 1,
                        "success": result.get("success", False),
                        "analysis_time": analysis_time,
                        "result_keys": list(result.keys()) if isinstance(result, dict) else [],
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    time.sleep(0.5)  # ë¶„ì„ ê°„ê²©
                    
                except Exception as e:
                    integrity_results.append({
                        "iteration": i + 1,
                        "success": False,
                        "error": str(e),
                        "timestamp": datetime.now().isoformat()
                    })
            
            # ê²°ê³¼ ì¼ê´€ì„± ê²€ì¦
            successful_results = [r for r in integrity_results if r.get("success", False)]
            
            if len(successful_results) < 2:
                consistency_check = False
                data_consistency = 0.0
            else:
                # ì²« ë²ˆì§¸ ì„±ê³µí•œ ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹„êµ
                baseline_result = successful_results[0]
                baseline_keys = set(baseline_result.get("result_keys", []))
                
                # ë‹¤ë¥¸ ê²°ê³¼ë“¤ê³¼ í‚¤ êµ¬ì¡° ë¹„êµ
                consistent_results = 0
                for result in successful_results[1:]:
                    result_keys = set(result.get("result_keys", []))
                    if baseline_keys == result_keys:
                        consistent_results += 1
                
                consistency_check = consistent_results == len(successful_results) - 1
                data_consistency = consistent_results / (len(successful_results) - 1) if len(successful_results) > 1 else 0.0
            
            # ì„±ëŠ¥ ì¼ê´€ì„± ê²€ì¦
            analysis_times = [r.get("analysis_time", 0) for r in successful_results]
            if analysis_times:
                avg_analysis_time = sum(analysis_times) / len(analysis_times)
                time_variance = max(analysis_times) - min(analysis_times)
                performance_consistent = time_variance < 2.0  # 2ì´ˆ ì´í•˜ ë³€ë™
            else:
                avg_analysis_time = 0
                performance_consistent = False
            
            # ì „ì²´ ì„±ê³µë¥ 
            success_rate = len(successful_results) / len(integrity_results) if integrity_results else 0
            
            results = {
                "total_iterations": len(integrity_results),
                "successful_iterations": len(successful_results),
                "success_rate": success_rate,
                "integrity_results": integrity_results,
                "consistency_analysis": {
                    "consistency_check": consistency_check,
                    "data_consistency": data_consistency,
                    "performance_consistent": performance_consistent,
                    "avg_analysis_time": avg_analysis_time,
                    "time_variance": time_variance if analysis_times else 0
                },
                "success": success_rate >= 0.8 and consistency_check,  # 80% ì´ìƒ ì„±ê³µí•˜ê³  ì¼ê´€ì„± ìœ ì§€
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì„±ê³µë¥ : {success_rate:.2%}, ì¼ê´€ì„±: {consistency_check})")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def run_comprehensive_stability_test(self) -> Dict[str, Any]:
        """ì¢…í•© ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸ›¡ï¸ ì¢…í•© ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            start_time = time.time()
            
            # 1. ì¥ì‹œê°„ ìš´ì˜ í…ŒìŠ¤íŠ¸
            long_running_results = self.long_running_test(hours=1)  # 1ì‹œê°„ í…ŒìŠ¤íŠ¸ (ì‹¤ì œë¡œëŠ” 5ë¶„)
            
            # 2. ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸
            error_recovery_results = self.error_recovery_test()
            
            # 3. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸
            memory_leak_results = self.memory_leak_test()
            
            # 4. ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸
            data_integrity_results = self.data_integrity_test()
            
            # ê²°ê³¼ í†µí•©
            total_time = time.time() - start_time
            
            # ì „ì²´ ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°
            stability_score = self._calculate_stability_score({
                "long_running": long_running_results,
                "error_recovery": error_recovery_results,
                "memory_leak": memory_leak_results,
                "data_integrity": data_integrity_results
            })
            
            self.stability_metrics = {
                "long_running": long_running_results,
                "error_recovery": error_recovery_results,
                "memory_leak": memory_leak_results,
                "data_integrity": data_integrity_results,
                "overall_score": stability_score,
                "total_test_time": total_time,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ì¢…í•© ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì ìˆ˜: {stability_score:.2f}/100)")
            return self.stability_metrics
            
        except Exception as e:
            logger.error(f"âŒ ì¢…í•© ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def _calculate_stability_score(self, results: Dict[str, Any]) -> float:
        """ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        max_score = 100.0
        
        # ì¥ì‹œê°„ ìš´ì˜ ì ìˆ˜ (30ì )
        long_running = results.get("long_running", {})
        if long_running.get("success", False):
            error_rate = long_running.get("error_rate", 0)
            score += (1 - error_rate) * 30
        
        # ì—ëŸ¬ ë³µêµ¬ ì ìˆ˜ (25ì )
        error_recovery = results.get("error_recovery", {})
        recovery_rate = error_recovery.get("recovery_success_rate", 0)
        score += recovery_rate * 25
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì ìˆ˜ (25ì )
        memory_leak = results.get("memory_leak", {})
        leak_detected = memory_leak.get("leak_analysis", {}).get("leak_detected", False)
        if not leak_detected:
            score += 25
        
        # ë°ì´í„° ë¬´ê²°ì„± ì ìˆ˜ (20ì )
        data_integrity = results.get("data_integrity", {})
        if data_integrity.get("success", False):
            consistency = data_integrity.get("consistency_analysis", {}).get("data_consistency", 0)
            score += consistency * 20
        
        return min(score, max_score)
    
    def get_stability_summary(self) -> Dict[str, Any]:
        """ì•ˆì •ì„± ê²€ì¦ ê²°ê³¼ ìš”ì•½"""
        if not self.stability_metrics:
            return {"error": "ì•ˆì •ì„± ê²€ì¦ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        return {
            "overall_stability_score": self.stability_metrics.get("overall_score", 0),
            "long_running_success": self.stability_metrics.get("long_running", {}).get("success", False),
            "error_recovery_success": self.stability_metrics.get("error_recovery", {}).get("success", False),
            "memory_leak_success": self.stability_metrics.get("memory_leak", {}).get("success", False),
            "data_integrity_success": self.stability_metrics.get("data_integrity", {}).get("success", False),
            "total_test_time": self.stability_metrics.get("total_test_time", 0),
            "timestamp": self.stability_metrics.get("timestamp", "")
        } 