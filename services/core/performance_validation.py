"""
Phase 5: ì„±ëŠ¥ ìµœì í™” ê²€ì¦ ëª¨ë“ˆ
Phase 4ì—ì„œ êµ¬í˜„ëœ ì„±ëŠ¥ ìµœì í™” íš¨ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import time
import logging
import psutil
import gc
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

from .performance_optimizer import PerformanceOptimizer
from .cache_service import CacheService
from .mock_unified_service import MockUnifiedMarketAnalysisService

logger = logging.getLogger(__name__)


class PerformanceValidation:
    """ì„±ëŠ¥ ìµœì í™” ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.performance_optimizer = PerformanceOptimizer()
        self.cache_service = CacheService()
        self.unified_service = MockUnifiedMarketAnalysisService()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
        self.performance_metrics = {}
        self.optimization_results = {}
        
    def validate_cache_optimization(self) -> Dict[str, Any]:
        """ìºì‹œ ìµœì í™” ê²€ì¦"""
        logger.info("ğŸ” ìºì‹œ ìµœì í™” ê²€ì¦ ì‹œì‘")
        
        try:
            # 1. ìºì‹œ íˆíŠ¸ìœ¨ í…ŒìŠ¤íŠ¸
            hit_rate_results = self._test_cache_hit_rate()
            
            # 2. ìºì‹œ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
            response_time_results = self._test_cache_response_time()
            
            # 3. ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
            memory_results = self._test_cache_memory_usage()
            
            # 4. ìºì‹œ ì •ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
            cleanup_results = self._test_cache_cleanup_efficiency()
            
            results = {
                "hit_rate": hit_rate_results,
                "response_time": response_time_results,
                "memory_usage": memory_results,
                "cleanup_efficiency": cleanup_results,
                "timestamp": datetime.now().isoformat()
            }
            
            # ì „ì²´ ìºì‹œ ìµœì í™” ì ìˆ˜ ê³„ì‚°
            overall_score = self._calculate_cache_optimization_score(results)
            results["overall_score"] = overall_score
            
            logger.info(f"âœ… ìºì‹œ ìµœì í™” ê²€ì¦ ì™„ë£Œ (ì ìˆ˜: {overall_score:.2f}/100)")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ìµœì í™” ê²€ì¦ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def _test_cache_hit_rate(self) -> Dict[str, Any]:
        """ìºì‹œ íˆíŠ¸ìœ¨ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_keys = [f"cache_test_{i}" for i in range(1000)]
        test_data = {"data": "test_value", "timestamp": datetime.now().isoformat()}
        
        # ìºì‹œ ì €ì¥
        start_time = time.time()
        for key in test_keys:
            self.cache_service.set(key, test_data)
        store_time = time.time() - start_time
        
        # ìºì‹œ ì¡°íšŒ (íˆíŠ¸ìœ¨ ì¸¡ì •)
        start_time = time.time()
        hit_count = 0
        miss_count = 0
        
        for key in test_keys:
            if self.cache_service.get(key):
                hit_count += 1
            else:
                miss_count += 1
        
        query_time = time.time() - start_time
        total_requests = hit_count + miss_count
        hit_rate = hit_count / total_requests if total_requests > 0 else 0
        
        return {
            "hit_count": hit_count,
            "miss_count": miss_count,
            "hit_rate": hit_rate,
            "total_requests": total_requests,
            "store_time": store_time,
            "query_time": query_time,
            "operations_per_second": total_requests / query_time if query_time > 0 else 0
        }
    
    def _test_cache_response_time(self) -> Dict[str, Any]:
        """ìºì‹œ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        test_key = "response_time_test"
        test_data = {"large_data": "x" * 10000}  # 10KB ë°ì´í„°
        
        # ìºì‹œ ì €ì¥ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        self.cache_service.set(test_key, test_data)
        store_time = time.time() - start_time
        
        # ìºì‹œ ì¡°íšŒ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        retrieved_data = self.cache_service.get(test_key)
        query_time = time.time() - start_time
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)
        db_query_time = 0.1  # 100ms ì‹œë®¬ë ˆì´ì…˜
        
        return {
            "store_time_ms": store_time * 1000,
            "query_time_ms": query_time * 1000,
            "db_query_time_ms": db_query_time * 1000,
            "speedup_ratio": db_query_time / query_time if query_time > 0 else 0,
            "data_size_kb": len(str(test_data)) / 1024
        }
    
    def _test_cache_memory_usage(self) -> Dict[str, Any]:
        """ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        process = psutil.Process()
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ëŒ€ìš©ëŸ‰ ìºì‹œ ë°ì´í„° ì €ì¥
        large_data = {}
        for i in range(1000):
            large_data[f"large_key_{i}"] = {
                "data": "x" * 1000,  # 1KB per item
                "timestamp": datetime.now().isoformat()
            }
        
        # ìºì‹œì— ì €ì¥
        for key, value in large_data.items():
            self.cache_service.set(key, value)
        
        # ì €ì¥ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        peak_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ìºì‹œ ì •ë¦¬
        self.cache_service.clear()
        
        # ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        return {
            "initial_memory_mb": initial_memory,
            "peak_memory_mb": peak_memory,
            "final_memory_mb": final_memory,
            "memory_increase_mb": peak_memory - initial_memory,
            "memory_recovery_mb": peak_memory - final_memory,
            "memory_efficiency": (peak_memory - initial_memory) / len(large_data) if large_data else 0
        }
    
    def _test_cache_cleanup_efficiency(self) -> Dict[str, Any]:
        """ìºì‹œ ì •ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        # ë§Œë£Œëœ ìºì‹œ í•­ëª© ìƒì„±
        expired_keys = []
        for i in range(100):
            key = f"expired_key_{i}"
            self.cache_service.set(key, {"data": "expired"}, ttl=1)  # 1ì´ˆ í›„ ë§Œë£Œ
            expired_keys.append(key)
        
        # ë§Œë£Œ ëŒ€ê¸°
        time.sleep(2)
        
        # ë§Œë£Œëœ í•­ëª© ì¡°íšŒ
        expired_count = 0
        for key in expired_keys:
            if not self.cache_service.get(key):
                expired_count += 1
        
        cleanup_efficiency = expired_count / len(expired_keys) if expired_keys else 0
        
        return {
            "total_expired_keys": len(expired_keys),
            "cleaned_keys": expired_count,
            "cleanup_efficiency": cleanup_efficiency,
            "cleanup_rate": cleanup_efficiency * 100
        }
    
    def _calculate_cache_optimization_score(self, results: Dict[str, Any]) -> float:
        """ìºì‹œ ìµœì í™” ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        max_score = 100.0
        
        # íˆíŠ¸ìœ¨ ì ìˆ˜ (40ì )
        hit_rate = results.get("hit_rate", {}).get("hit_rate", 0)
        score += min(hit_rate * 40, 40)
        
        # ì‘ë‹µ ì‹œê°„ ì ìˆ˜ (30ì )
        response_time = results.get("response_time", {})
        speedup_ratio = response_time.get("speedup_ratio", 0)
        score += min(speedup_ratio * 10, 30)
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì ìˆ˜ (20ì )
        memory_usage = results.get("memory_usage", {})
        memory_efficiency = memory_usage.get("memory_efficiency", 0)
        if memory_efficiency > 0:
            score += min(20 / memory_efficiency, 20)
        
        # ì •ë¦¬ íš¨ìœ¨ì„± ì ìˆ˜ (10ì )
        cleanup_efficiency = results.get("cleanup_efficiency", {}).get("cleanup_efficiency", 0)
        score += cleanup_efficiency * 10
        
        return min(score, max_score)
    
    def validate_batch_processing(self) -> Dict[str, Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦"""
        logger.info("ğŸ” ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦ ì‹œì‘")
        
        try:
            # 1. ë°°ì¹˜ í¬ê¸° ìµœì í™” í…ŒìŠ¤íŠ¸
            batch_size_results = self._test_batch_size_optimization()
            
            # 2. ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            batch_performance_results = self._test_batch_performance()
            
            # 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
            batch_memory_results = self._test_batch_memory_usage()
            
            # 4. ë™ì‹œì„± ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            batch_concurrency_results = self._test_batch_concurrency()
            
            results = {
                "batch_size_optimization": batch_size_results,
                "batch_performance": batch_performance_results,
                "batch_memory": batch_memory_results,
                "batch_concurrency": batch_concurrency_results,
                "timestamp": datetime.now().isoformat()
            }
            
            # ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì ìˆ˜ ê³„ì‚°
            overall_score = self._calculate_batch_processing_score(results)
            results["overall_score"] = overall_score
            
            logger.info(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ (ì ìˆ˜: {overall_score:.2f}/100)")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def _test_batch_size_optimization(self) -> Dict[str, Any]:
        """ë°°ì¹˜ í¬ê¸° ìµœì í™” í…ŒìŠ¤íŠ¸"""
        total_items = 1000
        batch_sizes = [10, 25, 50, 100, 200]
        
        results = {}
        for batch_size in batch_sizes:
            start_time = time.time()
            
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            for i in range(0, total_items, batch_size):
                batch = list(range(i, min(i + batch_size, total_items)))
                # ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
                time.sleep(0.001 * len(batch))  # ë°°ì¹˜ í¬ê¸°ì— ë¹„ë¡€í•œ ì²˜ë¦¬ ì‹œê°„
            
            processing_time = time.time() - start_time
            
            results[batch_size] = {
                "processing_time": processing_time,
                "items_per_second": total_items / processing_time if processing_time > 0 else 0,
                "efficiency": total_items / (processing_time * batch_size) if processing_time > 0 else 0
            }
        
        # ìµœì  ë°°ì¹˜ í¬ê¸° ì°¾ê¸°
        optimal_batch_size = max(results.keys(), 
                                key=lambda x: results[x]["items_per_second"])
        
        return {
            "batch_size_results": results,
            "optimal_batch_size": optimal_batch_size,
            "optimal_performance": results[optimal_batch_size]
        }
    
    def _test_batch_performance(self) -> Dict[str, Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # ìµœì  ë°°ì¹˜ í¬ê¸°ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        optimal_batch_size = 50
        total_items = 2000
        
        start_time = time.time()
        
        # ë°°ì¹˜ ì²˜ë¦¬
        processed_items = 0
        for i in range(0, total_items, optimal_batch_size):
            batch = list(range(i, min(i + optimal_batch_size, total_items)))
            # ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§
            processed_items += len(batch)
            time.sleep(0.001 * len(batch))
        
        processing_time = time.time() - start_time
        
        return {
            "total_items": total_items,
            "processed_items": processed_items,
            "batch_size": optimal_batch_size,
            "processing_time": processing_time,
            "items_per_second": processed_items / processing_time if processing_time > 0 else 0,
            "throughput": processed_items / processing_time if processing_time > 0 else 0
        }
    
    def _test_batch_memory_usage(self) -> Dict[str, Any]:
        """ë°°ì¹˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        process = psutil.Process()
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        batch_data = []
        for i in range(1000):
            batch_data.append({
                "id": i,
                "data": "x" * 1000,  # 1KB per item
                "timestamp": datetime.now().isoformat()
            })
        
        # ë°°ì¹˜ ì²˜ë¦¬
        peak_memory = 0
        for i in range(0, len(batch_data), 50):  # 50ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
            batch = batch_data[i:i+50]
            # ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
            current_memory = process.memory_info().rss / 1024 / 1024
            peak_memory = max(peak_memory, current_memory)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del batch_data
        gc.collect()
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        return {
            "initial_memory_mb": initial_memory,
            "peak_memory_mb": peak_memory,
            "final_memory_mb": final_memory,
            "memory_increase_mb": peak_memory - initial_memory,
            "memory_recovery_mb": peak_memory - final_memory,
            "memory_efficiency": (peak_memory - initial_memory) / len(batch_data) if batch_data else 0
        }
    
    def _test_batch_concurrency(self) -> Dict[str, Any]:
        """ë°°ì¹˜ ë™ì‹œì„± ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        total_batches = 10
        batch_size = 50
        
        def process_batch(batch_id):
            """ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜"""
            start_time = time.time()
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            batch_data = [f"item_{batch_id}_{i}" for i in range(batch_size)]
            time.sleep(0.1)  # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
            end_time = time.time()
            return {
                "batch_id": batch_id,
                "processing_time": end_time - start_time,
                "items_processed": len(batch_data)
            }
        
        # ìˆœì°¨ ì²˜ë¦¬
        sequential_start = time.time()
        sequential_results = []
        for i in range(total_batches):
            result = process_batch(i)
            sequential_results.append(result)
        sequential_time = time.time() - sequential_start
        
        # ë³‘ë ¬ ì²˜ë¦¬
        parallel_start = time.time()
        parallel_results = []
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(process_batch, i) for i in range(total_batches)]
            for future in as_completed(futures):
                result = future.result()
                parallel_results.append(result)
        parallel_time = time.time() - parallel_start
        
        # ì„±ëŠ¥ ë¹„êµ
        speedup = sequential_time / parallel_time if parallel_time > 0 else 0
        
        return {
            "sequential_time": sequential_time,
            "parallel_time": parallel_time,
            "speedup": speedup,
            "efficiency": speedup / 3 if speedup > 0 else 0,  # 3ê°œ ì›Œì»¤ ê¸°ì¤€
            "total_batches": total_batches,
            "batch_size": batch_size
        }
    
    def _calculate_batch_processing_score(self, results: Dict[str, Any]) -> float:
        """ë°°ì¹˜ ì²˜ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        max_score = 100.0
        
        # ë°°ì¹˜ í¬ê¸° ìµœì í™” ì ìˆ˜ (30ì )
        batch_size_results = results.get("batch_size_optimization", {})
        optimal_performance = batch_size_results.get("optimal_performance", {})
        items_per_second = optimal_performance.get("items_per_second", 0)
        score += min(items_per_second / 10, 30)
        
        # ë°°ì¹˜ ì„±ëŠ¥ ì ìˆ˜ (30ì )
        batch_performance = results.get("batch_performance", {})
        throughput = batch_performance.get("throughput", 0)
        score += min(throughput / 10, 30)
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì ìˆ˜ (20ì )
        batch_memory = results.get("batch_memory", {})
        memory_efficiency = batch_memory.get("memory_efficiency", 0)
        if memory_efficiency > 0:
            score += min(20 / memory_efficiency, 20)
        
        # ë™ì‹œì„± íš¨ìœ¨ì„± ì ìˆ˜ (20ì )
        batch_concurrency = results.get("batch_concurrency", {})
        efficiency = batch_concurrency.get("efficiency", 0)
        score += min(efficiency * 20, 20)
        
        return min(score, max_score)
    
    def validate_memory_optimization(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” ê²€ì¦"""
        logger.info("ğŸ” ë©”ëª¨ë¦¬ ìµœì í™” ê²€ì¦ ì‹œì‘")
        
        try:
            # 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
            memory_monitoring_results = self._test_memory_monitoring()
            
            # 2. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦
            memory_leak_results = self._test_memory_leak_detection()
            
            # 3. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íš¨ìœ¨ì„±
            gc_efficiency_results = self._test_garbage_collection()
            
            # 4. ë©”ëª¨ë¦¬ ì •ë¦¬ íš¨ìœ¨ì„±
            memory_cleanup_results = self._test_memory_cleanup()
            
            results = {
                "memory_monitoring": memory_monitoring_results,
                "memory_leak_detection": memory_leak_results,
                "garbage_collection": gc_efficiency_results,
                "memory_cleanup": memory_cleanup_results,
                "timestamp": datetime.now().isoformat()
            }
            
            # ì „ì²´ ë©”ëª¨ë¦¬ ìµœì í™” ì ìˆ˜ ê³„ì‚°
            overall_score = self._calculate_memory_optimization_score(results)
            results["overall_score"] = overall_score
            
            logger.info(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” ê²€ì¦ ì™„ë£Œ (ì ìˆ˜: {overall_score:.2f}/100)")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ê²€ì¦ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def _test_memory_monitoring(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸"""
        process = psutil.Process()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
        memory_samples = []
        for i in range(10):
            memory_info = process.memory_info()
            memory_samples.append({
                "rss_mb": memory_info.rss / 1024 / 1024,
                "vms_mb": memory_info.vms / 1024 / 1024,
                "timestamp": datetime.now().isoformat()
            })
            time.sleep(0.1)
        
        # í†µê³„ ê³„ì‚°
        rss_values = [sample["rss_mb"] for sample in memory_samples]
        vms_values = [sample["vms_mb"] for sample in memory_samples]
        
        return {
            "memory_samples": memory_samples,
            "rss_stats": {
                "min": min(rss_values),
                "max": max(rss_values),
                "avg": sum(rss_values) / len(rss_values),
                "current": rss_values[-1]
            },
            "vms_stats": {
                "min": min(vms_values),
                "max": max(vms_values),
                "avg": sum(vms_values) / len(vms_values),
                "current": vms_values[-1]
            }
        }
    
    def _test_memory_leak_detection(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦"""
        process = psutil.Process()
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
        leaked_objects = []
        for cycle in range(5):
            # ê°ì²´ ìƒì„± (ì¼ë¶€ëŠ” ëˆ„ìˆ˜)
            for i in range(100):
                obj = {"cycle": cycle, "data": "x" * 1000}
                leaked_objects.append(obj)
            
            # ì¼ë¶€ ê°ì²´ë§Œ ì •ë¦¬ (ëˆ„ìˆ˜ ì‹œë®¬ë ˆì´ì…˜)
            if cycle % 2 == 0:
                leaked_objects = leaked_objects[:-50]  # 50ê°œë§Œ ì •ë¦¬
        
        # ìµœì¢… ë©”ëª¨ë¦¬
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del leaked_objects
        gc.collect()
        
        cleaned_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        return {
            "initial_memory_mb": initial_memory,
            "final_memory_mb": final_memory,
            "cleaned_memory_mb": cleaned_memory,
            "memory_increase_mb": final_memory - initial_memory,
            "memory_recovery_mb": final_memory - cleaned_memory,
            "leak_detected": (final_memory - initial_memory) > 10  # 10MB ì´ìƒ ì¦ê°€ ì‹œ ëˆ„ìˆ˜ë¡œ íŒë‹¨
        }
    
    def _test_garbage_collection(self) -> Dict[str, Any]:
        """ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        # GC í†µê³„ ì´ˆê¸°í™”
        gc.collect()
        initial_stats = gc.get_stats()
        
        # ëŒ€ëŸ‰ ê°ì²´ ìƒì„±
        objects = []
        for i in range(10000):
            objects.append({"id": i, "data": "x" * 100})
        
        # ê°ì²´ ì°¸ì¡° í•´ì œ
        del objects
        
        # GC ì‹¤í–‰
        start_time = time.time()
        collected = gc.collect()
        gc_time = time.time() - start_time
        
        # GC í›„ í†µê³„
        final_stats = gc.get_stats()
        
        return {
            "objects_collected": collected,
            "gc_time": gc_time,
            "initial_stats": initial_stats,
            "final_stats": final_stats,
            "gc_efficiency": collected / gc_time if gc_time > 0 else 0
        }
    
    def _test_memory_cleanup(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        process = psutil.Process()
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ëŒ€ëŸ‰ ë°ì´í„° ìƒì„±
        large_data = []
        for i in range(5000):
            large_data.append({
                "id": i,
                "data": "x" * 2000,  # 2KB per item
                "timestamp": datetime.now().isoformat()
            })
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
        peak_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ìˆ˜ë™ ì •ë¦¬
        del large_data
        manual_cleanup_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # GC ê°•ì œ ì‹¤í–‰
        gc.collect()
        gc_cleanup_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        return {
            "initial_memory_mb": initial_memory,
            "peak_memory_mb": peak_memory,
            "manual_cleanup_mb": manual_cleanup_memory,
            "gc_cleanup_mb": gc_cleanup_memory,
            "manual_recovery_mb": peak_memory - manual_cleanup_memory,
            "gc_recovery_mb": peak_memory - gc_cleanup_memory,
            "cleanup_efficiency": (peak_memory - gc_cleanup_memory) / (peak_memory - initial_memory) if (peak_memory - initial_memory) > 0 else 0
        }
    
    def _calculate_memory_optimization_score(self, results: Dict[str, Any]) -> float:
        """ë©”ëª¨ë¦¬ ìµœì í™” ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        max_score = 100.0
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì ìˆ˜ (25ì )
        memory_monitoring = results.get("memory_monitoring", {})
        rss_stats = memory_monitoring.get("rss_stats", {})
        memory_variance = rss_stats.get("max", 0) - rss_stats.get("min", 0)
        if memory_variance < 50:  # 50MB ì´í•˜ ë³€ë™
            score += 25
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦ ì ìˆ˜ (30ì )
        memory_leak = results.get("memory_leak_detection", {})
        leak_detected = memory_leak.get("leak_detected", False)
        if not leak_detected:
            score += 30
        
        # GC íš¨ìœ¨ì„± ì ìˆ˜ (25ì )
        garbage_collection = results.get("garbage_collection", {})
        gc_efficiency = garbage_collection.get("gc_efficiency", 0)
        score += min(gc_efficiency / 1000, 25)
        
        # ì •ë¦¬ íš¨ìœ¨ì„± ì ìˆ˜ (20ì )
        memory_cleanup = results.get("memory_cleanup", {})
        cleanup_efficiency = memory_cleanup.get("cleanup_efficiency", 0)
        score += cleanup_efficiency * 20
        
        return min(score, max_score)
    
    def validate_overall_performance(self) -> Dict[str, Any]:
        """ì „ì²´ ì„±ëŠ¥ ê²€ì¦"""
        logger.info("ğŸ” ì „ì²´ ì„±ëŠ¥ ê²€ì¦ ì‹œì‘")
        
        try:
            # 1. ì‹œìŠ¤í…œ ì „ì²´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            system_performance = self._test_system_overall_performance()
            
            # 2. ì‚¬ìš©ì ê²½í—˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            user_experience = self._test_user_experience_performance()
            
            # 3. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
            resource_usage = self._test_resource_usage_performance()
            
            # 4. í™•ì¥ì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            scalability = self._test_scalability_performance()
            
            results = {
                "system_performance": system_performance,
                "user_experience": user_experience,
                "resource_usage": resource_usage,
                "scalability": scalability,
                "timestamp": datetime.now().isoformat()
            }
            
            # ì „ì²´ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            overall_score = self._calculate_overall_performance_score(results)
            results["overall_score"] = overall_score
            
            logger.info(f"âœ… ì „ì²´ ì„±ëŠ¥ ê²€ì¦ ì™„ë£Œ (ì ìˆ˜: {overall_score:.2f}/100)")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ì„±ëŠ¥ ê²€ì¦ ì‹¤íŒ¨ - {str(e)}")
            return {"error": str(e), "success": False}
    
    def _test_system_overall_performance(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì „ì²´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_symbols = ["005930.KS", "000660.KS", "005380.KS", "012450.KS", "034020.KS"]
        
        start_time = time.time()
        successful_analyses = 0
        total_analyses = len(test_symbols)
        
        for symbol in test_symbols:
            try:
                result = self.unified_service.analyze_single_stock_comprehensive(
                    ticker=symbol,
                    market_type="KOSPI",
                    timeframe="d"
                )
                if result.get("success", False):
                    successful_analyses += 1
            except Exception as e:
                logger.warning(f"ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì—ëŸ¬: {symbol} - {str(e)}")
        
        end_time = time.time()
        
        return {
            "total_analyses": total_analyses,
            "successful_analyses": successful_analyses,
            "success_rate": successful_analyses / total_analyses if total_analyses > 0 else 0,
            "total_processing_time": end_time - start_time,
            "average_processing_time": (end_time - start_time) / total_analyses if total_analyses > 0 else 0,
            "analyses_per_second": total_analyses / (end_time - start_time) if (end_time - start_time) > 0 else 0
        }
    
    def _test_user_experience_performance(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ê²½í—˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
        response_times = []
        
        for i in range(5):
            start_time = time.time()
            try:
                self.unified_service.analyze_single_stock_comprehensive(
                    ticker="005930.KS",
                    market_type="KOSPI",
                    timeframe="d"
                )
                response_time = time.time() - start_time
                response_times.append(response_time)
            except Exception as e:
                response_times.append(10.0)  # ì—ëŸ¬ ì‹œ 10ì´ˆë¡œ ì„¤ì •
        
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        
        # ì‚¬ìš©ì ê²½í—˜ ì ìˆ˜ ê³„ì‚°
        ux_score = 0
        if avg_response_time < 2.0:
            ux_score = 100
        elif avg_response_time < 5.0:
            ux_score = 80
        elif avg_response_time < 10.0:
            ux_score = 60
        else:
            ux_score = 40
        
        return {
            "response_times": response_times,
            "average_response_time": avg_response_time,
            "max_response_time": max_response_time,
            "ux_score": ux_score,
            "excellent_responses": len([rt for rt in response_times if rt < 2.0]),
            "good_responses": len([rt for rt in response_times if 2.0 <= rt < 5.0]),
            "poor_responses": len([rt for rt in response_times if rt >= 5.0])
        }
    
    def _test_resource_usage_performance(self) -> Dict[str, Any]:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        process = psutil.Process()
        
        # CPU ì‚¬ìš©ëŸ‰ ì¸¡ì •
        cpu_percent = process.cpu_percent(interval=1)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / 1024 / 1024
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        disk_usage = psutil.disk_usage('/')
        disk_percent = disk_usage.percent
        
        # ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ (ì‹œë®¬ë ˆì´ì…˜)
        network_usage = {
            "bytes_sent": 1024 * 1024,  # 1MB
            "bytes_recv": 2048 * 1024   # 2MB
        }
        
        # ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
        resource_score = 100
        
        if cpu_percent > 80:
            resource_score -= 30
        elif cpu_percent > 60:
            resource_score -= 15
        
        if memory_mb > 500:
            resource_score -= 30
        elif memory_mb > 300:
            resource_score -= 15
        
        if disk_percent > 90:
            resource_score -= 20
        elif disk_percent > 80:
            resource_score -= 10
        
        return {
            "cpu_percent": cpu_percent,
            "memory_mb": memory_mb,
            "disk_percent": disk_percent,
            "network_usage": network_usage,
            "resource_score": max(resource_score, 0)
        }
    
    def _test_scalability_performance(self) -> Dict[str, Any]:
        """í™•ì¥ì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸
        concurrent_requests = 5
        test_symbols = ["005930.KS", "000660.KS", "005380.KS", "012450.KS", "034020.KS"]
        
        def process_request(symbol):
            start_time = time.time()
            try:
                self.unified_service.analyze_single_stock_comprehensive(
                    ticker=symbol,
                    market_type="KOSPI",
                    timeframe="d"
                )
                return {"success": True, "time": time.time() - start_time}
            except Exception as e:
                return {"success": False, "time": time.time() - start_time, "error": str(e)}
        
        # ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=concurrent_requests) as executor:
            futures = [executor.submit(process_request, symbol) for symbol in test_symbols[:concurrent_requests]]
            results = [future.result() for future in as_completed(futures)]
        
        total_time = time.time() - start_time
        
        # ì„±ê³µë¥  ê³„ì‚°
        successful_requests = sum(1 for result in results if result["success"])
        success_rate = successful_requests / len(results) if results else 0
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„
        avg_processing_time = sum(result["time"] for result in results) / len(results) if results else 0
        
        # í™•ì¥ì„± ì ìˆ˜ ê³„ì‚°
        scalability_score = 0
        if success_rate >= 0.8 and avg_processing_time < 5.0:
            scalability_score = 100
        elif success_rate >= 0.6 and avg_processing_time < 10.0:
            scalability_score = 80
        elif success_rate >= 0.4:
            scalability_score = 60
        else:
            scalability_score = 40
        
        return {
            "concurrent_requests": concurrent_requests,
            "successful_requests": successful_requests,
            "success_rate": success_rate,
            "total_processing_time": total_time,
            "average_processing_time": avg_processing_time,
            "scalability_score": scalability_score
        }
    
    def _calculate_overall_performance_score(self, results: Dict[str, Any]) -> float:
        """ì „ì²´ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        max_score = 100.0
        
        # ì‹œìŠ¤í…œ ì„±ëŠ¥ ì ìˆ˜ (30ì )
        system_performance = results.get("system_performance", {})
        success_rate = system_performance.get("success_rate", 0)
        score += success_rate * 30
        
        # ì‚¬ìš©ì ê²½í—˜ ì ìˆ˜ (25ì )
        user_experience = results.get("user_experience", {})
        ux_score = user_experience.get("ux_score", 0)
        score += ux_score * 0.25
        
        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì ìˆ˜ (25ì )
        resource_usage = results.get("resource_usage", {})
        resource_score = resource_usage.get("resource_score", 0)
        score += resource_score * 0.25
        
        # í™•ì¥ì„± ì ìˆ˜ (20ì )
        scalability = results.get("scalability", {})
        scalability_score = scalability.get("scalability_score", 0)
        score += scalability_score * 0.2
        
        return min(score, max_score)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ê²€ì¦ ê²°ê³¼ ìš”ì•½"""
        if not self.performance_metrics:
            return {"error": "ì„±ëŠ¥ ê²€ì¦ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        return {
            "cache_optimization_score": self.performance_metrics.get("cache_optimization", {}).get("overall_score", 0),
            "batch_processing_score": self.performance_metrics.get("batch_processing", {}).get("overall_score", 0),
            "memory_optimization_score": self.performance_metrics.get("memory_optimization", {}).get("overall_score", 0),
            "overall_performance_score": self.performance_metrics.get("overall_performance", {}).get("overall_score", 0),
            "timestamp": datetime.now().isoformat()
        } 